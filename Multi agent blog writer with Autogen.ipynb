{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16836356-fd1e-4222-a0c0-f61abd5ab472",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8e9cc8-99f4-4546-a832-90897d423239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "import autogen\n",
    "from autogen import AssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72960348-5d67-44d6-b2c2-d54abe4aa2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \" \"\n",
    "azure_endpoint = \" \"\n",
    "api_version = \" \"\n",
    "\n",
    "llm_config = {\"api_key\": api_key, \"api_version\":api_version, \"azure_endpoint\":azure_endpoint, \"model\":\" \", \"api_type\":\"azure\", \"cache_seed\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e83a86f-bc44-445e-82b1-5972aad7b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def termination_msg(x):\n",
    "    return isinstance(x, dict) and \"TERMINATE\" == str(x.get(\"content\", \"\"))[-9:].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a63754-a9a0-4903-9c14-4d4c49de0597",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_generator = autogen.UserProxyAgent(\n",
    "    name=\"TopicsGenerator1\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False,  # we don't want to execute code in this case.\n",
    "    description=\"An Agent which generates topics for the article that it is asked to write\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdd41ce-b076-4a8f-b159-6047b65dc430",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_adder = AssistantAgent(\n",
    "    name=\"ExamplesAdder\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=\"You read the json having an article written. Your job is to add more examples in that json. Add a new key Examples and then add atleast 4 examples to it. \",\n",
    "    llm_config=llm_config,\n",
    "    description=\"Adding more examples\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb691618-65ee-4321-97bc-0eb876cec673",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_topic = AssistantAgent(\n",
    "    name=\"AdvancedTopic\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=\"You read the json having an article written. Your job is to add a new key which talks about advanced topics related to the article. Give final response in the same JSON format and then reply with TERMINATE\",\n",
    "    llm_config=llm_config,\n",
    "    description=\"Adding a section on Advanced Topics\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868322b5-bf50-4891-9bf3-bf4863274e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_writer = autogen.AssistantAgent(\n",
    "    name=\"ArticleWriter1\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=\"\"\"You are a technical blog writer, you write an article on the topics provided by TopicsGenerator. Each topic should be written with a simple example. Make sure the final response that you give should be in JSON format so that it can be rendered in the UI. It should follow an example structure given below:\n",
    "     \\{\n",
    "    \"Title\":\"Unraveling Numpy Broadcasting With Clear Examples\",\n",
    "    \"Body\":\\[\n",
    "        \\{\n",
    "            \"Content\": \"In the vibrant world of Python programming, Numpy stands as a fundamental library that empowers its users with extensive mathematical capabilities. Among these wonderful features of Numpy, a little appreciated yet pivotal one is 'Broadcasting'. This article will vividly explain and illustrate this fairly perplexing aspect of Numpy.\"\n",
    "        \\},\n",
    "        \\{\n",
    "            \"Heading\": \"What is Numpy Broadcasting?\",\n",
    "            \"Content\": \"Numpy broadcasting is a powerful feature that allows us to perform arithmetic operations on arrays of different shapes. This could be between a scalar and an array, or between arrays of different shapes, under certain conditions.\"\n",
    "        \\},\n",
    "        \\{\n",
    "            \"Content\": \"The concept behind broadcasting pivots on two rules:\",\n",
    "            \"List\": \\[\n",
    "                \\{\n",
    "                    \"ListItem\": \"If the arrays do not have the same rank, then a 1 will be pre-pended to the smaller ranking arrayâ€™s shape.\"\n",
    "                \\}\n",
    "            \\]\n",
    "        \\},\n",
    "        \\{\n",
    "            \"Heading\": \"Python example of Numpy Broadcasting\",\n",
    "            \"Content\": \"Let's illustrate this concept with a simple Python example.\",\n",
    "            \"Code\": \\[\n",
    "                \\{\n",
    "                    \"CodeBlock\": \"import numpy as np\\nA = np.array([1, 2, 3])\\nB = np.array([2, 2, 2])\\nC = A * B\\nprint(C)\"\n",
    "                \\},\n",
    "                \\{\n",
    "                    \"Content\": \"In this example, we're multiplying two arrays of identical shape, so broadcasting isn't necessary. However, observe what happens when we alter the second array:\",\n",
    "                    \"CodeBlock\": \"B = 2\\nC = A * B\\nprint(C)\"\n",
    "                \\}\n",
    "            \\]\n",
    "        \\}\n",
    "    \\]\n",
    "\\}\"\"\",\n",
    "    llm_config=llm_config,\n",
    "    description=\"technical blog writer who writes article on the list of topics provided\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2743ae5-bf48-463d-a5e0-329f2ce3da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reset_agents():\n",
    "    topics_generator.reset()\n",
    "    article_writer.reset()\n",
    "    examples_adder.reset()\n",
    "    advanced_topic.reset()\n",
    "    topics_generator.clear_history()\n",
    "    article_writer.clear_history()\n",
    "    examples_adder.clear_history()\n",
    "    advanced_topic.clear_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7f699-c533-4ffa-b2dc-de230250f9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_article(PROBLEM):\n",
    "    _reset_agents()\n",
    "    groupchat = autogen.GroupChat(\n",
    "        agents=[topics_generator, article_writer, examples_adder, advanced_topic],\n",
    "        messages=[],\n",
    "        max_round=4,\n",
    "        speaker_selection_method=\"round_robin\",\n",
    "        allow_repeat_speaker=False,\n",
    "        enable_clear_history=True\n",
    "    )\n",
    "    manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config, max_consecutive_auto_reply=1)\n",
    "    topics_generator.initiate_chat(\n",
    "        manager,\n",
    "        message=PROBLEM,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d223b5ec-9717-42cd-9bd1-70dc8027c02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "topics = [\"Comparative study of LangGraph, Autogen and Crewai for building multi-agent system.\"]\n",
    "final_json = []\n",
    "for i, topic in enumerate(topics):\n",
    "    PROBLEM = f\"Write an article similar to a blog on {topic}\"\n",
    "    create_article(PROBLEM)\n",
    "    cleaned_json_string = topics_generator.last_message()[\"content\"].replace(\"TERMINATE\", \"\").strip()\n",
    "    data = json.loads(cleaned_json_string)\n",
    "    final_json.append(data)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd4db9-d66f-49b2-aa34-0bc6e8e5afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = {}\n",
    "for f in final_json:\n",
    "    final = {**final, **f}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
